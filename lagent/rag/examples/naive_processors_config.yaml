# config/naive_processors_config.yaml

dependencies:
  llm:
    type: "lagent.llms.deepseek.DeepseekAPI"
    model_type: "deepseek-chat"
    key: "your_api_key"
    max_tokens: 4096

  embedder:
    type: "lagent.rag.nlp.sentence_transformer_embedder.SentenceTransformerEmbedder"
    model_name: 'all-MiniLM-L6-v2'
    device: 'cpu'  # 设备类型，设置为 "cpu"
    prefix: ""
    suffix: ""
    batch_size: 32
    normalize_embeddings: True
    model_path: 'sentence_transformer_min.pkl'

  storage:
    type: "lagent.rag.doc.storage.Storage"
    cache_dir: null   #使用默认值

  tokenizer:
    type: "lagent.rag.nlp.tokenizer.SimpleTokenizer"


processors:
  - type: "lagent.rag.processors.doc_parser.DocParser"
    params:
      cfg:
      storage: "storage"        # 引用依赖项名称
  - type: "lagent.rag.processors.chunk.ChunkSplitter"
    params:
      cfg:
        chunk_size: 1000
        overlap: 200
  - type: "lagent.rag.processors.build_db.BuildDatabase"
    params:
      embedder: "embedder"    # 依赖项
  - type: "lagent.rag.processors.dump_load.SaveGraph"
    params:
      storage: "storage"